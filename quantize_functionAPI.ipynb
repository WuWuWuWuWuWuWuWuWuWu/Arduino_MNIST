{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment && Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " C1 (Conv2D)                 (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " S2 (AveragePooling2D)       (None, 12, 12, 6)         0         \n",
      "                                                                 \n",
      " C3 (Conv2D)                 (None, 8, 8, 16)          2416      \n",
      "                                                                 \n",
      " S4 (AveragePooling2D)       (None, 4, 4, 16)          0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " F5 (Dense)                  (None, 120)               30840     \n",
      "                                                                 \n",
      " F6 (Dense)                  (None, 84)                10164     \n",
      "                                                                 \n",
      " exit_4 (Dense)              (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "augmentation = False\n",
    "quant = True\n",
    "exit = 4\n",
    "if(int(exit) > 4 or int(exit) < 1):\n",
    "    exit = 0\n",
    "if(augmentation == True):\n",
    "    model = tf.keras.models.load_model(\"/home/x/Desktop/augmentation_functionAPI/\")\n",
    "    tittle = \"aug_\" + str(exit)\n",
    "elif(augmentation == False):\n",
    "    model = tf.keras.models.load_model(\"/home/x/Desktop/Non_augmentation_functionAPI/\")\n",
    "    tittle = \"non_\" + str(exit)\n",
    "\n",
    "if(int(exit) < 5 and int(exit) > 0):\n",
    "    model = tf.keras.Model(inputs = model.layers[1].input, outputs = model.layers[7 + int(exit)].output)\n",
    "elif(int(exit) > 4 or int(exit) < 1):\n",
    "    model = tf.keras.Model(inputs = model.layers[1].input, outputs = [model.layers[7 + 1].output, model.layers[7 + 2].output, model.layers[7 + 3].output, model.layers[7 + 4].output])\n",
    "    \n",
    "model.summary()\n",
    "print(model.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.reshape(-1, 28 ,28, 1).astype(np.float32) / 255.0, x_test.reshape(-1, 28 ,28, 1).astype(np.float32) / 255.0\n",
    "if(augmentation == True):\n",
    "    train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range= 30, width_shift_range= 0.2, height_shift_range= 0.2, zoom_range= 0.2, data_format= 'channels_last', dtype= np.float32)\n",
    "elif(augmentation == False):\n",
    "    train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range= 0, width_shift_range= 0, height_shift_range= 0, zoom_range= 0, data_format= 'channels_last', dtype= np.float32)\n",
    "train_gen.fit(x_train)\n",
    "train_generator = train_gen.flow(x_train, y_train, batch_size= 10000, shuffle=True, seed=2, save_to_dir= None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(quant == False):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the unquantized/float model:\n",
    "    tflite_model_path = \"/home/x/Desktop/\" + tittle + \"_float32.tflite\"\n",
    "    with open(tflite_model_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    print('input: ', interpreter.get_input_details()[0]['dtype'])\n",
    "    print('output: ', interpreter.get_output_details()[0]['dtype'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgddc1ony/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgddc1ony/assets\n",
      "/home/x/.local/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-04-15 01:49:30.864570: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-04-15 01:49:30.864592: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-04-15 01:49:30.864697: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpgddc1ony\n",
      "2023-04-15 01:49:30.865530: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2023-04-15 01:49:30.865546: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: /tmp/tmpgddc1ony\n",
      "2023-04-15 01:49:30.868106: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-04-15 01:49:30.882427: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpgddc1ony\n",
      "2023-04-15 01:49:30.889165: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 24469 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n"
     ]
    }
   ],
   "source": [
    "if(quant == True):\n",
    "  def representative_data_gen():\n",
    "    x,y = train_generator.next()\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x).batch(1).take(100):\n",
    "      yield [input_value]\n",
    "\n",
    "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "  converter.representative_dataset = representative_data_gen\n",
    "  # Ensure that if any ops can't be quantized, the converter throws an error\n",
    "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "  # Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "  converter.inference_input_type = tf.uint8\n",
    "  converter.inference_output_type = tf.uint8\n",
    "  tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "if(quant == True):\n",
    "  # Save the quantized model:\n",
    "  tflite_model_quant_path = \"/home/x/Desktop/\" + tittle + \"_uint8.tflite\"\n",
    "  with open(tflite_model_quant_path, \"wb\") as f:\n",
    "      f.write(tflite_model_quant)\n",
    "  interpreter = tf.lite.Interpreter(model_content = tflite_model_quant)\n",
    "  print('input: ', interpreter.get_input_details()[0]['dtype'])\n",
    "  print('output: ', interpreter.get_output_details()[0]['dtype'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
